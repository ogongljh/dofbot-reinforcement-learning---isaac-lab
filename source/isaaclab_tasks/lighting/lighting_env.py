import math
import numpy as np
import gymnasium as gym
from gymnasium import spaces

from .lighting_config import (
    SAFE_DEG_LO, SAFE_DEG_HI, HOME_DEG, MAX_DELTA, CONTROL_REPEAT, DRIVE_VELOCITY,
    RANDOM_WARMUP_STEPS, CURRICULUM, HAND_Z_RANGE, MIN_SPAWN_DIST, MAX_XY_FROM_HAND,
    PATIENCE, MIN_STEPS_BEFORE_SUCCESS, SUCCESS_DIST, SUCCESS_ALIGN,
    PLANE_PATH, HAND_PATH, TRACKING_LIGHT_PATH, ROBOT_LIGHT_PATH, DOFBOT_PATH, JOINT_NAMES
)
from .lighting_utils import deg2rad, polar_sample, aim_pitch_deg
from .lighting_scene import LightingScene


class LightingEnv(gym.Env):
    metadata = {"render_modes": ["human"], "render_fps": 30}

    def __init__(self, world_path: str, sim_app, episode_steps=400, use_curriculum=True):
        super().__init__()
        self._sim_app = sim_app
        self._world_path = world_path
        self.episode_steps = int(episode_steps)
        self.use_curriculum = bool(use_curriculum)

        # â”€â”€ ì§€ì—° ì„í¬íŠ¸ (SimulationApp ì´í›„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try:
            from isaacsim.core import World
        except ImportError:
            from omni.isaac.core import World  # fallback
        try:
            from isaacsim import dynamic_control as dynamic_control
            _acquire_dc = dynamic_control.acquire_dynamic_control_interface
        except ImportError:
            from omni.isaac.dynamic_control import _dynamic_control as dynamic_control
            _acquire_dc = dynamic_control.acquire_dynamic_control_interface
        from pxr import Usd, PhysxSchema  # dofbot ìë™íƒìƒ‰ìš©

        # ---- action/obs ----
        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(4,), dtype=np.float32)
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(4 + 3 + 3 + 3 + 1,), dtype=np.float32
        )

        # âœ… 1) Stage (open) â†’ 2) World â†’ 3) DC ìˆœì„œ
        self.scene = LightingScene(
            sim_app=self._sim_app,
            world_path=self._world_path,
            plane_path=PLANE_PATH,
            hand_path=HAND_PATH,
            tracking_light_path=TRACKING_LIGHT_PATH,
            robot_light_path=ROBOT_LIGHT_PATH
        )

        self.world = World()
        self.world.reset();  self._sim_app.update()
        self.world.play();   self._sim_app.update()
        for _ in range(2):
            self.world.step(False); self._sim_app.update()

        self.dc = _acquire_dc()

        # ---- dofbot path ìë™ íƒìƒ‰ (fallback í¬í•¨)
        self.dof_path = self._find_dofbot_path(stage=self.scene.robot_light_prim.GetStage(),
                                               default=DOFBOT_PATH, Usd=Usd, PhysxSchema=PhysxSchema)
        self.art = self.dc.get_articulation(self.dof_path)
        if self.art is None:
            raise RuntimeError(f"âŒ Articulation not found at {self.dof_path}. ê²½ë¡œ/ì‹œë®¬ ìƒíƒœ í™•ì¸.")

        self.joint_names = JOINT_NAMES
        self.joints = [self.dc.find_articulation_dof(self.art, n) for n in self.joint_names]
        if any(h == 0 for h in self.joints):
            raise RuntimeError("âŒ One or more DOF handles invalid. Check joint names / USD.")

        # ---- joint limits & safe ranges ----
        self.joint_limits = []
        for h in self.joints:
            props = self.dc.get_dof_properties(h)
            if getattr(props, "hasLimits", False):
                lo = float(np.array(getattr(props, "lower")).reshape(-1)[0])
                hi = float(np.array(getattr(props, "upper")).reshape(-1)[0])
            else:
                lo, hi = -math.pi, math.pi
            self.joint_limits.append((lo, hi))
        self.joint_limits = np.array(self.joint_limits, dtype=np.float32)

        self.sim_safe_lo = np.maximum(deg2rad(SAFE_DEG_LO), self.joint_limits[:, 0])
        self.sim_safe_hi = np.minimum(deg2rad(SAFE_DEG_HI), self.joint_limits[:, 1])

        # ğŸ”’ í•˜ë“œê°€ë“œ (ì „ë°©ë§Œ, ì¶©ë¶„íˆ ìˆ™ì¼ ìˆ˜ ìˆê²Œ ë„“ê²Œ): joint2~4 = [-120Â°, ìƒí•œì€ config ë°˜ì˜]
        for i in (1, 2, 3):
            self.sim_safe_lo[i] = max(self.sim_safe_lo[i], np.radians(-120.0))
            # ìƒí•œì€ lighting_configì—ì„œ ì´ë¯¸ -5/-10degë¡œ ì œí•œë¨

        self.home_pose = deg2rad(HOME_DEG)

        # ---- control params ----
        self.max_delta = np.asarray(MAX_DELTA, dtype=np.float32)
        self.control_repeat = int(CONTROL_REPEAT)
        self.drive_velocity = float(DRIVE_VELOCITY)
        self.random_warmup_steps = int(RANDOM_WARMUP_STEPS)

        # ì•¡ì…˜â†’ì¡°ì¸íŠ¸ ë¶€í˜¸ ë§¤í•‘
        self.joint_sign = np.array([+1, -1, -1, -1], dtype=np.float32)

        # ë¡œë´‡ ë¼ì´íŠ¸ ì•ë°©í–¥ ë¶€í˜¸ (ë¦¬ì…‹ ë•Œ dot ê¸°ì¤€ìœ¼ë¡œ ì¦‰ì‹œ í™•ì •)
        self._fwd_sign = +1.0

        # ---- episode state ----
        self.episode_idx = 0
        self._step_count = 0
        self._no_improve_count = 0
        self.best_reward = -1e9
        self.prev_q = None

        # curriculum & spawn
        self.spawn_radius = float(CURRICULUM[0][1])
        self.hand_z_min, self.hand_z_max = HAND_Z_RANGE
        self.min_spawn_dist = float(MIN_SPAWN_DIST)
        self.max_xy_from_hand = float(MAX_XY_FROM_HAND)

        self.patience = int(PATIENCE)
        self.min_steps_before_success = int(MIN_STEPS_BEFORE_SUCCESS)
        self.success_dist = float(SUCCESS_DIST)
        self.success_align = float(SUCCESS_ALIGN)

        # ---- ê²½ê³„ ì—¬ìœ í­(ì•ˆì „ ë§ˆì§„) â”€â”€ (ì¦ê°€)
        self._EPS_BOUND = np.radians(1.0)  # 1.0Â°
        self._EPS_NEAR  = np.radians(1.0)  # 1.0Â°

        # ğŸ”§ ë³´ìƒ/ì¢…ë£Œ ë³´ì¡° ìƒíƒœ
        self._prev_align = 0.0
        self._bad_align_count = 0

        # ğŸ”§ ë³´ìƒ shaping ìƒíƒœ (Î”ê±°ë¦¬/Î”ì •ë ¬ ê³„ì‚°ìš©)
        self._prev_dist = None
        self._prev_align_for_r = None

    # ---------- ë‚´ë¶€ ìœ í‹¸ ----------
    def _find_dofbot_path(self, stage, default, Usd, PhysxSchema):
        prim = stage.GetPrimAtPath(default)
        if prim and prim.IsValid():
            return default
        for c in ["/World/dofbot", "/World/DOFBOT", "/World/dofbot/dofbot"]:
            p = stage.GetPrimAtPath(c)
            if p and p.IsValid():
                return c
        for p in stage.Traverse():
            try:
                if p.HasAPI(PhysxSchema.PhysxArticulationRootAPI):
                    return p.GetPath().pathString
            except Exception:
                continue
        raise RuntimeError("âŒ DOFBOT articulation primì„ Stageì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. lighting_config.DOFBOT_PATH í™•ì¸.")

    def _apply_curriculum(self):
        if not self.use_curriculum:
            return
        ep = self.episode_idx
        for th, r in CURRICULUM:
            if ep >= th:
                self.spawn_radius = float(r)

    def _move_to_home(self, max_steps=400, tol=1e-3):
        jitter = (np.random.uniform(-1.0, 1.0, size=4).astype(np.float32)) * np.radians(4.0)
        q_home = (self.home_pose + jitter).astype(np.float32)
        for h, q in zip(self.joints, q_home):
            self.dc.set_dof_position_target(h, float(q))
            self.dc.set_dof_velocity_target(h, self.drive_velocity)
        for _ in range(int(max_steps)):
            self.world.step(False); self._sim_app.update()
            cur = np.array([self.dc.get_dof_position(h) for h in self.joints], dtype=np.float32)
            if float(np.max(np.abs(cur - q_home))) < tol:
                break
        for h in self.joints:
            self.dc.set_dof_velocity_target(h, 0.0)

    # ---------- Gym API ----------
    def reset(self, seed=None, options=None):
        super().reset(seed=None)

        self._step_count = 0
        self._no_improve_count = 0
        self.best_reward = -1e9
        self._apply_curriculum()

        # shaping ìƒíƒœ ì´ˆê¸°í™”
        self._prev_dist = None
        self._prev_align_for_r = None

        # ì•ˆì „ ë²”ìœ„ ë‚´ ëœë¤ ì´ˆê¸°ìì„¸(ê²½ê³„ ë§ˆì§„ ì ìš©)
        margin = np.radians(3.0)
        q_lo = self.sim_safe_lo + margin
        q_hi = self.sim_safe_hi - margin

        # ğŸ”§ ì´ˆê¸°ìì„¸ ì „ë°©(ìŒìˆ˜) ìƒ˜í”Œ ê°•í™”: joint2~4 ìƒí•œ ë” ë‚®ì¶° ìƒ˜í”Œë§
        for i in (1, 2, 3):
            q_hi[i] = min(q_hi[i], np.radians(-5.0))

        q0 = np.random.uniform(q_lo, q_hi).astype(np.float32)

        for h, q in zip(self.joints, q0):
            self.dc.set_dof_position_target(h, float(q))
            self.dc.set_dof_velocity_target(h, self.drive_velocity)

        for _ in range(30):
            self.world.step(False); self._sim_app.update()
        for h in self.joints:
            self.dc.set_dof_velocity_target(h, 0.0)

        # tracking light ì´ˆê¸°í™”
        self.scene.cache_tracking_base()
        lx0, ly0, lz0 = self.scene.tracking_base

        cx, cy, cz = self.scene.get_plane_center()
        rl = self.scene.get_robot_light_world_pos()

        fake = None
        for _ in range(40):
            rx, ry = polar_sample(cx, cy, 0.3*self.spawn_radius, self.spawn_radius, self.np_random)
            rz = float(self.np_random.uniform(self.hand_z_min, self.hand_z_max)) + cz
            if math.dist((rx, ry, rz), rl) >= self.min_spawn_dist:
                fake = (rx, ry, rz); break
        if fake is None:
            fake = (rx, ry, rz)
        self.scene.set_hand_pos(*fake)

        dx, dy = fake[0] - lx0, fake[1] - ly0
        dxy = math.hypot(dx, dy)
        if dxy > self.max_xy_from_hand:
            nx, ny = dx/dxy, dy/dxy
            nlx, nly = fake[0] - nx*self.max_xy_from_hand, fake[1] - ny*self.max_xy_from_hand
        else:
            nlx, nly = lx0, ly0
        pitch = aim_pitch_deg((nlx, nly, lz0), fake)
        self.scene.set_tracking_light_pose(nlx, nly, lz0, pitch)

        for _ in range(3):
            self.world.step(False); self._sim_app.update()

        # ì•ë°©í–¥ ë¶€í˜¸ ì¦‰ì‹œ í™•ì •
        self.prev_q = np.array([self.dc.get_dof_position(h) for h in self.joints], dtype=np.float32)
        fwd = self.scene.get_robot_light_forward()
        toT, _ = self.scene.get_vec_robot_to_hand()
        dot = float(fwd[0]*toT[0] + fwd[1]*toT[1] + fwd[2]*toT[2])
        self._fwd_sign = +1.0 if dot >= 0.0 else -1.0
        print(f"[CALIB] forward_sign={self._fwd_sign:+.0f} (dot={dot:.3f})")

        # ğŸ”§ ë³´ì¡° ìƒíƒœ ì´ˆê¸°í™”
        align0, _ = self._forward_alignment()
        self._prev_align = align0
        self._bad_align_count = 0

        self.episode_idx += 1
        print(f"[RESET] ep={self.episode_idx} q0(deg)={np.degrees(self.prev_q)}")

        obs = self._get_obs()
        return obs, {}

    def step(self, action):
        if self._step_count < self.random_warmup_steps:
            action = self.action_space.sample().astype(np.float32)
        else:
            action = np.asarray(action, dtype=np.float32)

        # ìŠ¤ì¼€ì¼ë§ (+ ë¶€í˜¸ ë§µ ì ìš©)
        d_sim = (np.clip(action, -1.0, 1.0) * self.max_delta) * self.joint_sign

        hit_limit = 0
        tgt_cmd = np.zeros(4, dtype=np.float32)  # ë¡œê·¸ìš© íƒ€ê¹ƒ ê¸°ë¡

        # â”€â”€ ê²½ê³„ ì•ˆì „ ë§ˆì§„(EPS) ì ìš© + ìµœì†Œ ê°€ë™í­ ë³´ì¥ + ê²½ê³„ ê·¼ì ‘ ë°˜ì „ ê°€ë“œ â”€â”€
        MIN_SPAN = np.radians(5.0)
        for i, h in enumerate(self.joints):
            cur = self.dc.get_dof_position(h)
            lo_hw, hi_hw = self.joint_limits[i]

            lo_raw = float(self.sim_safe_lo[i])
            hi_raw = float(self.sim_safe_hi[i])

            lo = max(lo_hw, lo_raw + self._EPS_BOUND)
            hi = min(hi_hw, hi_raw - self._EPS_BOUND)

            if hi - lo < MIN_SPAN:
                mid = 0.5 * (lo + hi)
                lo = mid - 0.5 * MIN_SPAN
                hi = mid + 0.5 * MIN_SPAN

            near_hi = (cur >= hi - self._EPS_NEAR) and (d_sim[i] > 0)
            near_lo = (cur <= lo + self._EPS_NEAR) and (d_sim[i] < 0)
            if near_hi or near_lo:
                d_sim[i] = -abs(d_sim[i]) if near_hi else abs(d_sim[i])

            tgt = float(cur + float(d_sim[i]))
            tgt = float(np.clip(tgt, lo, hi))

            if tgt <= lo + 1e-6 or tgt >= hi - 1e-6:
                hit_limit += 1

            self.dc.set_dof_position_target(h, tgt)
            tgt_cmd[i] = tgt

        # ì†ë„ ê±¸ê³  ì‹œë®¬ ìŠ¤í…
        for h in self.joints:
            self.dc.set_dof_velocity_target(h, self.drive_velocity)
        for _ in range(self.control_repeat):
            self.world.step(False); self._sim_app.update()
        for h in self.joints:
            self.dc.set_dof_velocity_target(h, 0.0)

        # tracking light ì¡°ì¤€ ìœ ì§€
        fx, fy, fz = self.scene.get_hand_pos()
        lx0, ly0, lz0 = self.scene.tracking_base
        dx, dy = fx - lx0, fy - ly0
        dxy = math.hypot(dx, dy)
        if dxy > self.max_xy_from_hand:
            nx, ny = dx/dxy, dy/dxy
            nlx, nly = fx - nx*self.max_xy_from_hand, fy - ny*self.max_xy_from_hand
        else:
            nlx, nly = lx0, ly0
        pitch = aim_pitch_deg((nlx, nly, lz0), (fx, fy, fz))
        self.scene.set_tracking_light_pose(nlx, nly, lz0, pitch)

        # ê´€ì¸¡/ë¦¬ì›Œë“œ
        obs = self._get_obs()
        reward = self._compute_reward()

        # ì„±ê³µ/ì¢…ë£Œ íŒì •ìš© ì •ë ¬/ê±°ë¦¬
        align, dist = self._forward_alignment()

        dalign = align - self._prev_align
        self._prev_align = align

        if align < 0.0:
            self._bad_align_count += 1
        else:
            self._bad_align_count = 0

        self._step_count += 1
        success_ready = (self._step_count >= self.min_steps_before_success)
        success = success_ready and (dist <= self.success_dist) and (align >= self.success_align)

        # ë² ìŠ¤íŠ¸ ë¦¬ì›Œë“œ ê°±ì‹  ê¸°ë°˜ ì¸ë‚´ì‹¬
        if reward > self.best_reward + 1e-3:
            self.best_reward = reward
            self._no_improve_count = 0
        else:
            self._no_improve_count += 1

        # ì •ì§€(ìŠ¤í†¨) ê°ì§€
        q = np.array([self.dc.get_dof_position(h) for h in self.joints], dtype=np.float32)
        dq = float(np.max(np.abs(q - self.prev_q))) if self.prev_q is not None else 0.0
        self.prev_q = q.copy()
        stalled = dq < 1e-4

        # âœ… ì„±ê³µ ë³´ë„ˆìŠ¤ + ì‹œê°„ ë³´ë„ˆìŠ¤
        if success:
            success_bonus = 10.0
            time_bonus = 1.0 - (self._step_count / self.episode_steps)
            reward += success_bonus + 0.5 * time_bonus

        terminated = bool(success)

        # âœ… ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì™„í™” (íˆíŠ¸/ì •ë ¬)
        truncated = (
            (self._step_count >= self.episode_steps) or
            ((hit_limit >= 4) and (self._step_count > 60)) or   # was 3 & >30
            (self._no_improve_count >= self.patience) or
            (stalled and self._no_improve_count >= 200)
        )

        # âœ… ë‚˜ìœ ì •ë ¬ì— ëŒ€í•œ ì¸ë‚´ì‹¬ ì™„í™”
        bad_align_patience = 25  # was 6
        truncated = truncated or (self._bad_align_count >= bad_align_patience)

        # â”€â”€ ë””ë²„ê¹…: í˜„ì¬ê°’/íƒ€ê¹ƒ/ê±°ë¦¬/ì •ë ¬/ë¦¬ì›Œë“œ ì¶œë ¥ â”€â”€
        cur_now = [self.dc.get_dof_position(h) for h in self.joints]
        print(
            "[STEP] ep={} t={} cur(deg)={} tgt(deg)={} hit={} dist={:.3f} align={:.3f} rew={:.3f}".format(
                self.episode_idx,
                self._step_count - 1,
                np.degrees(cur_now),
                np.degrees(tgt_cmd),
                hit_limit,
                dist, align, float(reward),
            )
        )

        edge_cnt = int(np.sum((q <= (self.sim_safe_lo + self._EPS_BOUND)) |
                            (q >= (self.sim_safe_hi - self._EPS_BOUND))))
        info = {
            "dist": dist,
            "align": align,
            "hit_limit": hit_limit,
            "saturation_rate": float(edge_cnt / 4.0),
            "step": self._step_count,
            "reward": float(reward),
            "dalign": float(dalign),
        }
        return obs, float(reward), terminated, truncated, info


    # ---------- obs/reward ----------
    def _get_obs(self):
        jp = np.array([self.dc.get_dof_position(h) for h in self.joints], dtype=np.float32)
        hx, hy, hz = self.scene.get_hand_pos()
        rx, ry, rz = self.scene.get_robot_light_world_pos()
        vx, vy, vz = (hx - rx), (hy - ry), (hz - rz)
        dist = float(math.sqrt(vx*vx + vy*vy + vz*vz))
        return np.array([*jp, hx, hy, hz, rx, ry, rz, vx, vy, vz, dist], dtype=np.float32)

    def _forward_alignment(self):
        """ë¼ì´íŠ¸ ë¡œì»¬ -Z(ì•)ê³¼ ë¡œë´‡â†’íƒ€ê²Ÿ ë‹¨ìœ„ ë²¡í„°ì˜ ë‚´ì ([-1,1]) ë°˜í™˜."""
        fwd = self.scene.get_robot_light_forward()
        fwd = (self._fwd_sign * fwd[0], self._fwd_sign * fwd[1], self._fwd_sign * fwd[2])
        toT, d = self.scene.get_vec_robot_to_hand()
        align = float(fwd[0]*toT[0] + fwd[1]*toT[1] + fwd[2]*toT[2])
        return align, d

    def _posture_prior(self, q, align_raw):
        ahead = (align_raw >= 0.0)
        idxs = [1, 2, 3]
        pen = 0.0
        for i in idxs:
            qi = float(q[i])
            if ahead:
                if qi > 0:
                    pen += np.tanh(abs(qi))
            else:
                if qi < 0:
                    pen += np.tanh(abs(qi))
        return pen

    def _compute_reward(self):
        align, d = self._forward_alignment()
        jp = np.array([self.dc.get_dof_position(h) for h in self.joints], dtype=np.float32)

        # --- Potential-based shaping: Î”ê±°ë¦¬/Î”ì •ë ¬ ---
        if self._prev_dist is None:
            self._prev_dist = d
        if self._prev_align_for_r is None:
            self._prev_align_for_r = align

        d_dist   = self._prev_dist - d            # ê°€ê¹Œì›Œì§€ë©´ +
        d_align  = align - self._prev_align_for_r # ì •ë©´ìœ¼ë¡œ ëŒë©´ +
        self._prev_dist = d
        self._prev_align_for_r = align

        # --- ê¸°ë³¸ í•­ëª© ---
        r_align = align
        r_dalign = d_align

        # ë„ˆë¬´ ë¶™ìœ¼ë©´ ë²Œì 
        r_close = -max(0.0, 0.03 - d) * 6.0

        # âœ… ê²½ê³„ íŒ¨ë„í‹° ì™„í™”
        near_low  = jp <= (self.sim_safe_lo + self._EPS_BOUND)
        near_high = jp >= (self.sim_safe_hi - self._EPS_BOUND)
        edge_cnt = int(np.sum(near_low | near_high))
        r_edge = -1.0 * edge_cnt   # was -2.5

        # ì†Œí”„íŠ¸ ë°°ë¦¬ì–´
        qmid = 0.5 * (self.sim_safe_lo + self.sim_safe_hi)
        qspan = (self.sim_safe_hi - self.sim_safe_lo) + 1e-6
        closeness = np.maximum(0.0, 0.8 - np.abs((jp - qmid) / (0.5 * qspan)))
        r_soft_barrier = -1.0 * float(np.sum(closeness))

        # âœ… í–‰ë™ ìŠ¤ë¬´ë”© ì™„í™”
        if self.prev_q is not None:
            dq_vec = jp - self.prev_q
            r_smooth = -0.5 * float(np.sum(dq_vec * dq_vec))  # was -2.0
        else:
            r_smooth = 0.0

        # 2~4 ë¶€í˜¸ prior(ì•½í•˜ê²Œ)
        post_pen = self._posture_prior(jp, align)

        # --- ê°€ì¤‘ì¹˜ ë°¸ëŸ°ìŠ¤ ---
        w_d_dist  = 2.0
        w_align   = 1.0
        w_d_align = 0.5
        w_post    = 0.03

        back_soft = -0.3 * max(0.0, -align)

        reward = (
            w_d_dist * d_dist
            + w_align * r_align
            + w_d_align * r_dalign
            + r_close
            + r_edge
            + r_soft_barrier
            + r_smooth
            + back_soft
            - w_post * post_pen
        )

        # ë² ì´ìŠ¤ ê³¼íšŒì „ ì–µì œ(ì™„ë§Œ)
        base_pen = 0.01 * abs(jp[0])
        reward -= base_pen

        # âœ… ë¦¬ì›Œë“œ í´ë¦¬í•‘(ìŠ¤ì¼€ì¼ ì•ˆì •í™”)
        reward = np.clip(reward, -5.0, 5.0)
        return float(reward)


    def render(self):  # not used
        pass
